{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python 201.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nível intermediário em Python\n",
    "\n",
    "Os notebooks dessa segunda etapa, focam especificamente em features intermediárias/avançadas da linguagem.\n",
    "\n",
    "Tenha em mente que algumas questões apresentadas neste notebook, farão referência aos arquivos .py encontrados dentro do diretório src no mesmo nível."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paralelismo e Concorrência\n",
    "\n",
    "A linguagem de programação python tem um histórico bem antigo relacioado a estruturas de processamento paralelo e concorrência.\n",
    "\n",
    "Uma das grandes reclamações de muitos programadores da linguagem é a reconhecida [GIL (Global Interpreter Lock)](https://realpython.com/python-gil/). Diferente de outras linguagens que tem [Garbage Collector](https://en.wikipedia.org/wiki/Garbage_collection_(computer_science)), Python utiliza-se de outro modelo para verificar se as variáveis tem algum tipo de referência, chamado de [Reference Counting](https://en.wikipedia.org/wiki/Reference_counting).\n",
    "\n",
    "> *The Python Global Interpreter Lock or GIL, in simple words, is a mutex (or a lock) that allows only one thread to hold the control of the Python interpreter.*\n",
    "\n",
    "Dessa maneira o uso da linguagem acaba por impor algumas restrições na questão de paralelismo. Devido a restrição da GIL, todo programa em Python é executado em apenas uma única thread (nos mesmos moldes de javascript por exemplo). Podemos criar diversas threads em python, mas elas acabem por ser escalonadas para serem executadas uma por vez, tendo uma alternância entre elas.\n",
    "\n",
    "![Threading](../../img/thread.png)\n",
    "\n",
    "Neste sentido a linguagem acaba por implementar outro tipo de estrutura para a criação de paralelismo, ao invés de criarmos diversas threads, podemos criar diversos processos.\n",
    "\n",
    "Uma das grandes diferenças é que não existe no caso dos processos memória compartilhada, evitando assim [Race Conditions](https://en.wikipedia.org/wiki/Race_condition). Outra diferença é que os processos encapsulam todo uma nova estrutura do interpretador python, ocasionando assim um gasto extra de processamento e memória.\n",
    "\n",
    "> P.S.: Esta sendo implementado na versão 3.8 da linguagem, uma maneira de se compartilhar memória entre processos.\n",
    "\n",
    "Apesar de tudo, ambas as threads e process tem sua valia... a regra de ouro é:\n",
    " - Caso seu programa faça uso intensido de processamento (CPU), utilize processos, pois ele escalonará melhor seu código, fazendo-o executar mais rápido.\n",
    " - Se, for utilizado I/O ou Network Access por exemplo, neste sentido a melhor opção são threads!\n",
    " - Assim, como o caso acima, veremos também o uso das keywords async/await que podem ser usadas para substituir o uso das threads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### concurrent.futures\n",
    "\n",
    "Infelizmente em python existem algumas formas de se usar threads e processos (ver referências), mas nas últimas versões da linguagem foi criada uma estrutura bem simples e direta para a execução de código e é esta estrutura que vamos apresentar aqui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T12:10:29.158550Z",
     "start_time": "2019-05-10T12:10:29.154161Z"
    }
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T12:13:38.118058Z",
     "start_time": "2019-05-10T12:13:38.078647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "NUMBERS = range(0, 2)\n",
    "\n",
    "def cpu_heavy(x):\n",
    "    count = 0\n",
    "    for i in range(x**2):\n",
    "        count += i**2\n",
    "\n",
    "def threading_example(fn=cpu_heavy, chunksize=100):\n",
    "    \"\"\"Threaded version: 8 threads.\"\"\"\n",
    "    items = []\n",
    "    # Melhores práticas sugerem que max_workers para thread deve ser n = m * num_cores\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        items = executor.map(fn, NUMBERS, chunksize=chunksize)\n",
    "    return list(items)\n",
    "\n",
    "def processing_example(fn=cpu_heavy, chunksize=100):\n",
    "    \"\"\"Multiprocessed version: 4 'threads'.\"\"\"\n",
    "    items = []\n",
    "    # Melhores práticas sugerem que max_workers para process deve ser n = num_cores\n",
    "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        items = executor.map(fn, NUMBERS, chunksize=chunksize)\n",
    "    return list(items)\n",
    "\n",
    "def normal_example(fn=cpu_heavy):\n",
    "    \"\"\"Single threaded version.\"\"\"\n",
    "    items = []\n",
    "    for i in NUMBERS:\n",
    "        items.append(fn(i))\n",
    "    return items\n",
    "\n",
    "ex1, ex2, ex3 = threading_example(), processing_example(), normal_example()\n",
    "print(ex1==ex2)\n",
    "print(ex1==ex3)\n",
    "print(ex2==ex3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### %timeit\n",
    "\n",
    "No Jupyter Notebook podemos executar um método mágico chamado timeit (o mesmo pode ser executado via linha de comando para testar scripts em python).\n",
    "\n",
    "Este método executa nosso código e retorna o tempo que levou para o mesmo ser executado. Vamos utilizar aqui para demonstrar em termos de performance de execução quais das 3 funções acabam por ter melhor performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T12:14:17.734080Z",
     "start_time": "2019-05-10T12:13:43.987848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.55 s ± 642 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.24 s ± 17.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.13 s ± 50.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "NUMBERS = range(0, 250)\n",
    "\n",
    "%timeit threading_example(fn=cpu_heavy)\n",
    "%timeit processing_example(fn=cpu_heavy)\n",
    "%timeit normal_example(fn=cpu_heavy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I/O Bound\n",
    "\n",
    "Caso nosso método de nome **cpu_heavy** tivesse muito I/O (como acesso a rede), neste caso o ideal é utilizar threading.\n",
    "\n",
    "Para exemplificar, criamos o método **io_heavy**, o qual fará um HTTP GET (usando a biblioteca requests), e retorna verdadeiro ou falso caso a url seja encontrada.\n",
    "\n",
    "Devido a peculiaridade da função **io_heavy**, o **chunksize** utilizado deve ser o padrão (o qual é 1)... isso porque caso contrário não dividiremos corretamente a carga, o que ocasionaria perda de performance, principalmente na versão com **ProcessPoolExecutor** (faça o teste, aumente o chunksize para 5 por exemplo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T12:14:17.740577Z",
     "start_time": "2019-05-10T12:14:17.735859Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def io_heavy(x):\n",
    "    r = requests.get('https://google.com.br')\n",
    "    if r.status_code == 200:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T12:16:58.208179Z",
     "start_time": "2019-05-10T12:15:29.509575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24 s ± 186 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.54 s ± 102 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "5.28 s ± 1.53 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "NUMBERS = range(0, 10)\n",
    "\n",
    "%timeit threading_example(fn=io_heavy, chunksize=1)\n",
    "%timeit processing_example(fn=io_heavy, chunksize=1)\n",
    "%timeit normal_example(fn=io_heavy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AsyncIO\n",
    "\n",
    "Em versões mais modernas da linguagem Python, os desenvolvedores podem utilizar novas keywords para realizar a concorrência de suas aplicações. Em muitas outras linguagens esse conceito de Asynchronous I/O e Event Loop é bem conhecido.\n",
    "\n",
    "Em versões novas da linguagem Javascript é possível utilizar praticamente as mesmas keywords e permitir que seu código se torne concorrente!\n",
    "\n",
    "Para exemplificar o uso, vamos modificar nosso código io_heavy. Detalhe importante, que todo o código assíncrono usando as keywords async/await deve ser usando em processamento de rotinas que são I/O bound, nos mesmos moldes do módulo ThreadPoolExecutor, visto acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-10T13:22:50.212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.33 µs ± 108 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import requests\n",
    "\n",
    "async def aio_heavy(x):\n",
    "    r = requests.get('https://google.com.br')\n",
    "    await asyncio.sleep(1)\n",
    "    if r.status_code == 200:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "async def asyncio_example(NUMBERS):\n",
    "    items = []\n",
    "    for i in NUMBERS:\n",
    "        item = await aio_heavy(i)\n",
    "        items.append(item)\n",
    "    return items\n",
    "\n",
    "def main():\n",
    "    NUMBERS = range(0, 10)\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.create_task(asyncio_example(NUMBERS))\n",
    "\n",
    "%timeit main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como este código fora executado dentro do Jupyter Notebook, e o mesmo já possui um event loop sendo executado, foram utilizadas as linhas com as funções **get_event_loop** e **create_task**.\n",
    "\n",
    "Para exemplificar de forma natural (caso não tivéssemos um event loop já sendo executado), acesse a "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referências\n",
    " - [Understanding the Python GIL](https://www.dabeaz.com/python/UnderstandingGIL.pdf)\n",
    " - [What is the Python Global Interpreter Lock (GIL)?](https://realpython.com/python-gil/)\n",
    " - [An Intro to Threading in Python](https://realpython.com/intro-to-python-threading/)\n",
    " - [Speed Up Your Python Program With Concurrency](https://realpython.com/python-concurrency/)\n",
    " - [Async IO in Python: A Complete Walkthrough](https://realpython.com/async-io-python/)\n",
    " - [threading - Manage concurrent threads](https://pymotw.com/3/threading/index.html)\n",
    " - [multiprocessing - Manage Processes Like Threads](https://pymotw.com/3/multiprocessing/index.html)\n",
    " - [asyncio - Asynchronous I/O, event loop, and concurrency tools](https://pymotw.com/3/asyncio/index.html)\n",
    " - [concurrent.futures - Manage Pools of Concurrent Tasks](https://pymotw.com/3/concurrent.futures/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "49px",
    "width": "250px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
